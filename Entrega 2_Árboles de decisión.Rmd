---
title: "Proyecto 2. Entrega 2. Árboles de decisión"
author: 
  - "Pablo Daniel Barillas Moreno, Carné No. 22193"
  - "Mathew Cordero Aquino, Carné No. 22982"
output:
  pdf_document:
    latex_engine: xelatex
  html_document: default
date: "2025-02-02"
header-includes:
   - \usepackage{fvextra}
   - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
repository: "https://github.com/DanielBarillas/Proyecto-2_Entrega-2_MineriaDeDatos_Grupo-1.git"
---

### Enlace al Repositorio del proyecto 2 - Entrega 2 de minería de datos del Grupo #1
[Repositorio en GitHub](https://github.com/DanielBarillas/Proyecto-2_Entrega-2_MineriaDeDatos_Grupo-1.git)

### 0. Descargue los conjuntos de datos. 

Para este punto, ya se ha realizado el proceso para descargar del sitio web: [House Prices - Advanced Regression Techniques](https://kaggle.com/competitions/house-prices-advanced-regression-techniques), la data de entrenamiento y la data de prueba, ambos extraídos desde la carpeta "house_prices_data/" en data frames llamados train_data (data de entrenamiento) y test_data (data de prueba), sin convertir automáticamente las variables categóricas en factores (stringsAsFactors = FALSE). Luego, se realiza una inspección inicial de train_data mediante tres funciones: head(train_data), que muestra las primeras filas del dataset; str(train_data), que despliega la estructura del data frame, incluyendo el tipo de cada variable; y summary(train_data), que proporciona un resumen estadístico de las variables numéricas y una descripción general de las categóricas.

```{r}
train_data <- read.csv("house_prices_data/train.csv", stringsAsFactors = FALSE)
test_data <- read.csv("house_prices_data/test.csv", stringsAsFactors = FALSE)

head(train_data)   # Muestra las primeras filas
str(train_data)    # Muestra la estructura del dataset
summary(train_data) # Resumen estadístico
```
### 1. Use los mismos conjuntos de entrenamiento y prueba que usó para los modelos de regresión lineal en la entrega anterior. 

```{r}
# Cargar librerías necesarias
library(readr)
library(dplyr)

# Fijar semilla para reproducibilidad
set.seed(42)

# Cargar los conjuntos de datos
train_set <- read_csv("house_prices_data/train.csv", show_col_types = FALSE)
test_set <- read_csv("house_prices_data/test.csv", show_col_types = FALSE)

# Verificar dimensiones
cat("Dimensiones del conjunto de entrenamiento:", dim(train_set), "\n")
cat("Dimensiones del conjunto de prueba:", dim(test_set), "\n")

# Mostrar los primeros registros
head(train_set)
head(test_set)

# Resumen estadístico de cada conjunto
summary(train_set)
summary(test_set)

# Verificar los tipos de datos en cada conjunto
str(train_set)
str(test_set)
```
### 2. Elabore un árbol de regresión para predecir el precio de las casas usando todas las variables.

```{r}
# Cargar librerías necesarias
library(rpart)
library(rpart.plot)
library(caret)
library(dplyr)
library(ggplot2)

# Cargar conjunto de datos
train_set <- read.csv("house_prices_data/train.csv", stringsAsFactors = TRUE)

# Revisar estructura y resumen de los datos
str(train_set)
summary(train_set)

# Eliminar la columna Id (no es una variable predictora)
if ("Id" %in% colnames(train_set)) {
  train_set <- train_set %>% select(-Id)
}

# Convertir variables categóricas a factores si es necesario
categorical_vars <- names(train_set)[sapply(train_set, is.character)]
train_set[categorical_vars] <- lapply(train_set[categorical_vars], as.factor)

# Dividir `train_set` en un conjunto de entrenamiento (80%) y prueba (20%)
set.seed(42) # Para reproducibilidad
train_index <- createDataPartition(train_set$SalePrice, p = 0.8, list = FALSE)
train_data <- train_set[train_index, ]
test_data <- train_set[-train_index, ]

# Crear el árbol de regresión con el nuevo conjunto de entrenamiento
set.seed(42)
arbol_regresion <- rpart(SalePrice ~ ., data = train_data, method = "anova")

# Visualizar el árbol de regresión
rpart.plot(arbol_regresion, type = 3, fallen.leaves = TRUE, cex = 0.6, main = "Árbol de Regresión para Predicción de Precio de Casas")

# Evaluación del modelo
predicciones_train <- predict(arbol_regresion, newdata = train_data)
mse_train <- mean((train_data$SalePrice - predicciones_train)^2, na.rm = TRUE)
cat("Error cuadrático medio en entrenamiento (MSE):", mse_train, "\n")

predicciones_test <- predict(arbol_regresion, newdata = test_data)
mse_test <- mean((test_data$SalePrice - predicciones_test)^2, na.rm = TRUE)
cat("Error cuadrático medio en prueba (MSE):", mse_test, "\n")

# Comparar predicciones con valores reales
ggplot(data.frame(Real = test_data$SalePrice, Predicho = predicciones_test), aes(x = Real, y = Predicho)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_abline(slope = 1, intercept = 0, col = "red", linetype = "dashed") +
  labs(title = "Predicción del Árbol de Regresión vs Valores Reales",
       x = "Precio Real",
       y = "Precio Predicho") +
  theme_minimal()
```
**Análisis del Árbol de Regresión y Resultados**

**2.1. Interpretación del Árbol de Regresión**

El árbol de regresión construido tiene como objetivo predecir el precio de las casas utilizando todas las variables disponibles en el conjunto de datos. La estructura del árbol nos permite identificar qué variables tienen mayor influencia en la predicción del precio y cómo se segmentan los diferentes valores de las propiedades. A partir de la imagen del árbol, se pueden extraer varios hallazgos clave:

**2.1.1. División Principal:**

- La primera división del árbol está determinada por la variable OverallQual (calidad general de la casa). Esto indica que la calidad de construcción y los materiales utilizados son el principal factor que influye en el precio de las casas.

- **Si OverallQual < 8**, el árbol sigue subdividiendo por variables como GrLivArea (área habitable en pies cuadrados), Neighborhood (vecindario) y BsmtFinSF1 (área terminada del sótano). Esto sugiere que para casas de calidad media o baja, el precio está más condicionado por el tamaño de la casa y su ubicación.

- **Si OverallQual ≥ 8**, la predicción del precio se guía por GrLivArea y YearBuilt (año de construcción). Esto significa que para casas de mayor calidad, las dimensiones de la propiedad y el año de construcción juegan un papel fundamental en la determinación del precio.

**2.2. Segmentación por Tamaño y Ubicación:**

- **Para casas con OverallQual < 7**, el precio tiende a ser más bajo y se ve influenciado principalmente por GrLivArea y Neighborhood. Esto sugiere que, en propiedades de menor calidad, la ubicación y el tamaño son factores determinantes en la variación del precio.

- **Para casas con OverallQual ≥ 9**, el precio tiende a ser significativamente más alto, y el árbol segmenta aún más las predicciones basándose en GrLivArea y Neighborhood. Esto implica que en propiedades de lujo, el tamaño de la casa y su ubicación en vecindarios de prestigio juegan un papel clave en la valorización de la propiedad.

- *Vecindarios como NoRidge y StoneBr aparecen en la parte superior de la jerarquía de segmentación para las casas más costosas, lo que indica que las propiedades en estas zonas tienden a tener precios más elevados.

**2.3. Análisis del Desempeño del Modelo**

El rendimiento del modelo se evalúa mediante el error cuadrático medio (MSE), el cual nos indica qué tan lejos están las predicciones del modelo en relación con los valores reales de las casas.

- **MSE en entrenamiento**: 1,297,581,895
- **MSE en prueba**: 1,658,823,049

Un aspecto importante a notar es que el MSE en prueba es mayor que el MSE en entrenamiento. Esto sugiere que el modelo tiene una alta varianza, lo que significa que puede estar sobreajustado a los datos de entrenamiento. Un modelo sobreajustado tiende a aprender demasiado bien los patrones del conjunto de entrenamiento, pero pierde capacidad de generalización cuando se le presentan nuevos datos en el conjunto de prueba.

La diferencia entre los errores nos indica que el modelo podría estar capturando demasiado ruido en el entrenamiento, lo cual podría corregirse mediante técnicas como la poda del árbol o el ajuste de hiperparámetros para reducir la complejidad del modelo.

**2.4. Evaluación de Predicciones vs Valores Reales**

En la segunda imagen proporcionada, se muestra un gráfico de dispersión donde el eje X representa los valores reales del precio de las casas y el eje Y representa los valores predichos por el modelo.

- **Línea roja diagonal**: Representa la relación ideal entre las predicciones y los valores reales. Si todas las predicciones fueran perfectas, los puntos estarían alineados sobre esta línea.

- **Puntos azules dispersos**: Indican cómo se distribuyen las predicciones del modelo en relación con los valores reales.

A partir de la gráfica podemos notar:

2.4.1. **Buena predicción en el rango medio de precios**: Para casas con precios dentro de un rango medio, el modelo parece tener una precisión aceptable, ya que varios puntos están cercanos a la línea roja.

2.4.2. **Dificultad con valores extremos**: Para casas con precios extremadamente altos o bajos, el modelo tiene una mayor dispersión, lo que indica que sus predicciones son menos precisas. Esto es un indicio de que el modelo no está capturando completamente la variabilidad de los precios en los extremos.

2.4.3. **Subestimación de precios altos**: Algunas casas de precios elevados aparecen con valores predichos mucho más bajos de lo esperado. Esto sugiere que el modelo tiene dificultades para capturar correctamente los factores que hacen que una casa tenga un precio significativamente alto.

2.4.4. **Sobreestimación en algunos casos**: También hay algunos casos en los que el modelo sobreestima el precio de casas de menor valor, indicando que podría estar considerando características menos relevantes como altamente influyentes.

**2.5. Conclusiones y Recomendaciones**

El modelo identifica correctamente los principales factores que afectan el precio de una casa:

2.5.1.**OverallQual (calidad de la casa) es la variable más relevante**.

- GrLivArea (tamaño habitable) y Neighborhood (vecindario) también tienen un impacto clave.
- YearBuilt (año de construcción) influye más en casas de mayor calidad.

2.5.2. **El modelo tiene un MSE relativamente alto, lo que indica margen de mejora**:

- La diferencia entre el MSE en entrenamiento y en prueba sugiere sobreajuste.

- Se podría mejorar utilizando técnicas como poda del árbol, validación cruzada o ajuste de hiperparámetros para reducir la varianza.

2.5.3. **El modelo funciona bien para precios en el rango medio, pero tiene problemas con valores extremos**:

- Predice bien precios intermedios, pero subestima valores altos y tiene errores en casos de precios muy bajos.

- Se podría explorar la inclusión de interacciones entre variables o utilizar modelos más avanzados como Random Forest o Gradient Boosting para mejorar la precisión.

2.5.4. **El modelo es interpretable y proporciona información útil sobre la influencia de diferentes características en el precio de las casas**:

- A diferencia de modelos más complejos como redes neuronales o ensembles, los árboles de decisión permiten una visualización clara de cómo se toman las decisiones de predicción.

- Sin embargo, esta ventaja de interpretabilidad viene a costa de menor precisión en las predicciones.

**Recomendaciones para Mejorar el Modelo**

- Para mejorar el desempeño del modelo y obtener predicciones más precisas, se pueden considerar los siguientes enfoques:

- **Poda del árbol**: Reducir el tamaño del árbol eliminando divisiones poco significativas para evitar sobreajuste.

- **Uso de Random Forest o Gradient Boosting**: Árboles de regresión individuales pueden ser inestables, mientras que métodos basados en ensambles pueden mejorar la precisión al combinar múltiples árboles.

- **Feature Engineering**: Investigar si transformar algunas variables o agregar nuevas combinaciones de variables podría mejorar las predicciones.

- **Validación Cruzada**: Evaluar el modelo con validación cruzada para asegurarse de que su rendimiento es consistente en diferentes subconjuntos de datos.

**Conclusión Final**

El árbol de regresión construido proporciona una buena interpretación de los factores clave que afectan el precio de las casas. Sin embargo, su precisión es limitada, especialmente en valores extremos. El modelo tiene un nivel de error considerable, indicando que aunque captura bien algunas tendencias generales, no generaliza de manera óptima para todas las observaciones. Mejoras adicionales pueden hacerse mediante poda del árbol o exploración de modelos más sofisticados como Random Forest o Gradient Boosting.

### 3. Úselo para predecir y analice el resultado. ¿Qué tal lo hizo? 

```{r}
# Cargar librerías necesarias
library(rpart)
library(rpart.plot)
library(caret)
library(dplyr)
library(ggplot2)

# Cargar conjunto de datos
train_set <- read.csv("house_prices_data/train.csv", stringsAsFactors = TRUE)

# Eliminar la columna de Id (ya que no aporta a la predicción)
if ("Id" %in% colnames(train_set)) {
  train_set <- train_set %>% select(-Id)
}

# Convertir variables categóricas a factores si es necesario
categorical_vars <- names(train_set)[sapply(train_set, is.character)]
train_set[categorical_vars] <- lapply(train_set[categorical_vars], as.factor)

# Dividir el conjunto de entrenamiento en training (80%) y test (20%)
set.seed(42)
train_index <- createDataPartition(train_set$SalePrice, p = 0.8, list = FALSE)
train_data <- train_set[train_index, ]
test_data <- train_set[-train_index, ]

# Crear el modelo de árbol de regresión
set.seed(42)
arbol_regresion <- rpart(SalePrice ~ ., data = train_data, method = "anova")

# Visualizar el árbol de decisión
rpart.plot(arbol_regresion, type = 3, fallen.leaves = TRUE, cex = 0.6, main = "Árbol de Regresión para Predicción de Precio de Casas")

# Evaluación del modelo en entrenamiento
predicciones_train <- predict(arbol_regresion, newdata = train_data)
mse_train <- mean((train_data$SalePrice - predicciones_train)^2, na.rm = TRUE)
cat("Error cuadrático medio en entrenamiento (MSE):", mse_train, "\n")

# Evaluación del modelo en prueba
predicciones_test <- predict(arbol_regresion, newdata = test_data)
mse_test <- mean((test_data$SalePrice - predicciones_test)^2, na.rm = TRUE)
cat("Error cuadrático medio en prueba (MSE):", mse_test, "\n")

# Comparar predicciones con valores reales
ggplot(data.frame(Real = test_data$SalePrice, Predicho = predicciones_test), aes(x = Real, y = Predicho)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_abline(slope = 1, intercept = 0, col = "red", linetype = "dashed") +
  labs(title = "Predicción del Árbol de Regresión vs Valores Reales",
       x = "Precio Real",
       y = "Precio Predicho") +
  theme_minimal()
```
**Análisis y Evaluación del Modelo de Árbol de Regresión**

**3.1.Evaluación del Desempeño con el Error Cuadrático Medio (MSE)**

**MSE en entrenamiento**: 1,297,581,895
**MSE en prueba**: 1,658,823,049

El error cuadrático medio en prueba es considerablemente mayor que en entrenamiento, lo que indica que el modelo podría estar sobreajustado a los datos de entrenamiento y no generaliza bien a nuevos datos.

**3.2. Interpretación del Árbol de Regresión**

El árbol de regresión muestra que las variables más importantes para la predicción del precio de las casas son:

- **OverallQual (Calidad general de la casa)**: Es la primera división del árbol, lo que indica que es el factor más influyente.

- **GrLivArea (Área habitable en pies cuadrados por encima del suelo)**: También tiene un impacto significativo en la segmentación.

- **Neighborhood (Barrio en el que se encuentra la casa)**: Determina la segmentación en varias ramas del árbol.

- **BsmtFinSF1 (Área del sótano terminado) y YearBuilt (Año de construcción de la casa)**: También son importantes en las ramas finales del árbol.

Estos criterios de división nos dicen que el precio de una casa se ve afectado en gran medida por la calidad de construcción, el tamaño habitable y la ubicación.

**3.3. Interpretación del Gráfico de Predicciones vs Valores Reales**

3.3.1. **Tendencia lineal visible, pero dispersión alta**:

- Aunque existe una correlación entre los valores reales y predichos, hay una gran dispersión, especialmente en precios altos.

- Esto sugiere que el modelo no es preciso para valores atípicos (casas muy caras o muy baratas).

3.3.2. **Subestimación de precios altos**:

- Se observa que el modelo tiende a subestimar los precios de casas caras (muchos puntos están por debajo de la línea roja).

- Esto indica que el modelo no captura bien las características que elevan el precio de las casas más costosas.

**3.4. Conclusiones y Posibles Mejoras**

3.4.1. **El modelo no generaliza bien**:

- La diferencia entre el MSE de entrenamiento y prueba indica sobreajuste.

- Posible solución: Poda del árbol de decisión para evitar que sea demasiado complejo.

3.4.2. **Los valores atípicos afectan el desempeño**:

- Casas de precio muy alto tienen predicciones más imprecisas.

- Posible solución: Aplicar transformación logarítmica a SalePrice para reducir la variabilidad.

3.4.3. **Podría beneficiarse de modelos más avanzados**:

- Un árbol de decisión simple tiene limitaciones.

**Alternativas más robustas**:

- Random Forest (bosques aleatorios) para mejorar la generalización.

- Gradient Boosting para capturar mejor la relación entre variables.

**Conclusión Final**

El árbol de regresión logra capturar algunas relaciones clave en la predicción del precio de las casas, pero presenta sobreajuste y dificultad en valores extremos. Para mejorar el modelo, se recomienda poda del árbol, transformación de variables y probar modelos más avanzados como Random Forest o Gradient Boosting.

### 4. Haga, al menos, 3 modelos más, cambiando el parámetro de la profundidad del árbol. ¿Cuál es el mejor modelo para predecir el precio de las casas? 

```{r}
# Cargar librerías necesarias
library(rpart)
library(rpart.plot)
library(caret)
library(dplyr)
library(ggplot2)

# Cargar conjunto de datos
train_set <- read.csv("house_prices_data/train.csv", stringsAsFactors = TRUE)

# Dividir en train y test (80%-20%)
set.seed(42)
trainIndex <- createDataPartition(train_set$SalePrice, p = 0.8, list = FALSE)
train_data <- train_set[trainIndex, ]
test_data <- train_set[-trainIndex, ]

# Función para entrenar y evaluar modelos con diferentes profundidades
evaluar_modelo <- function(cp_value, maxdepth) {
  modelo <- rpart(SalePrice ~ ., data = train_data, method = "anova",
                  control = rpart.control(cp = cp_value, maxdepth = maxdepth))
  
  # Predicciones en conjunto de prueba
  predicciones_test <- predict(modelo, newdata = test_data)
  mse_test <- mean((test_data$SalePrice - predicciones_test)^2, na.rm = TRUE)
  
  # Graficar el árbol
  cat("Modelo con maxdepth =", maxdepth, "- MSE en prueba:", mse_test, "\n")
  rpart.plot(modelo, main = paste("Árbol de Regresión (maxdepth =", maxdepth, ")"))
  
  return(list(modelo = modelo, mse_test = mse_test))
}

# Crear y evaluar tres modelos con diferentes profundidades
set.seed(42)
modelo1 <- evaluar_modelo(cp_value = 0.01, maxdepth = 3)  # Árbol poco profundo
modelo2 <- evaluar_modelo(cp_value = 0.01, maxdepth = 5)  # Árbol intermedio
modelo3 <- evaluar_modelo(cp_value = 0.01, maxdepth = 8)  # Árbol más complejo

# Comparación de los modelos
mse_values <- data.frame(
  Modelo = c("MaxDepth 3", "MaxDepth 5", "MaxDepth 8"),
  MSE = c(modelo1$mse_test, modelo2$mse_test, modelo3$mse_test)
)

ggplot(mse_values, aes(x = Modelo, y = MSE)) +
  geom_col(fill = "steelblue") +
  geom_text(aes(label = round(MSE, 0)), vjust = -0.5) +
  labs(title = "Comparación de Modelos con Diferente Profundidad",
       x = "Modelo",
       y = "Error Cuadrático Medio (MSE)") +
  theme_minimal()
```
**Análisis de los Modelos con Diferente Profundidad**

A partir de los resultados obtenidos en la comparación de los modelos con distintas profundidades, podemos extraer las siguientes conclusiones:

**4.1. Comportamiento de los Modelos**

**MaxDepth 3**:

- El modelo con una profundidad de 3 tiene el MSE más alto (1,989,007,643).

- Esto indica que el árbol es demasiado simple y no captura bien la complejidad del problema.

- Al ser poco profundo, no logra modelar correctamente las relaciones entre las variables y los precios de las casas.

**MaxDepth 5**:

- Redujo significativamente el error con un MSE de 1,658,823,049.

- Indica que el modelo empieza a capturar relaciones más relevantes sin sobreajustar.

- Es una mejora notable en comparación con el modelo más simple.

**MaxDepth 8**:

- Tiene el mismo MSE que el modelo con profundidad 5 (1,658,823,049).

- Esto sugiere que aumentar la profundidad no mejora el rendimiento, sino que estabiliza el error.

- Podría ser un signo de sobreajuste en el conjunto de entrenamiento, ya que la ganancia de precisión en los datos de prueba es nula.

**4.2. ¿Cuál es el Mejor Modelo?**

**El modelo con MaxDepth 5 parece ser la mejor opción**.

- Reduce significativamente el error en comparación con MaxDepth 3.

- No muestra mejora adicional al aumentar la profundidad a 8.

- Balancea bien la capacidad predictiva y la generalización sin caer en sobreajuste.

**4.3. ¿Por qué no seguir aumentando la profundidad?**

- Profundidades mayores podrían llevar al modelo a memorizar los datos de entrenamiento, perdiendo capacidad de generalización.

- El hecho de que MaxDepth 8 tenga el mismo MSE que MaxDepth 5 indica que más profundidad no aporta mejoras en los datos de prueba.

- Se podría optimizar aún más probando poda (prune()) o ajustando el parámetro cp para reducir el número de nodos irrelevantes.

**Conclusión Final**

- Profundidad 3 (maxdepth = 3) → Alto MSE, indicando un modelo subajustado (underfitting).

- Profundidad 5 (maxdepth = 5) → MSE menor, mejor ajuste.

- Profundidad 8 (maxdepth = 8) → MSE similar a maxdepth = 5, sin grandes mejoras, indicando posible sobreajuste (overfitting).

Por lo tanto, el mejor modelo sería el de profundidad 5 (maxdepth = 5), ya que logra un buen equilibrio entre precisión y generalización.

### 5. Compare los resultados con el modelo de regresión lineal de la hoja anterior, ¿cuál lo hizo mejor? 

**Comparación del Modelo de Regresión Lineal y el Árbol de Regresión**

Para evaluar cuál modelo predice mejor el precio de las casas, analizamos la métrica del Error Cuadrático Medio (MSE) en el conjunto de prueba. El MSE mide la diferencia promedio al cuadrado entre los valores predichos y los valores reales, donde un valor menor indica un mejor desempeño del modelo.

**5.1. Resultados del MSE**

A partir de los cálculos realizados en ambas entregas, obtenemos los siguientes valores de MSE para los modelos evaluados:

**Modelo de Regresión Lineal (Mejor modelo: Ridge Regression)**

**MSE en prueba**:

1.02 × 10⁹ (Extraído de la Serie 12 en la entrega proyecto 2. Entrega 1)

**MSE en entrenamiento**:

Inferior al de prueba, lo que indica un buen ajuste sin sobreajuste significativo.

**Modelo de Árbol de Regresión (Mejor modelo: Profundidad 5)**

**MSE en prueba**:

1.65 × 10⁹
 
**MSE en entrenamiento**:

1.29 × 10⁹, lo que sugiere que el modelo ajusta bien los datos de entrenamiento, pero en la prueba su desempeño disminuye considerablemente.

**5.2. Análisis Comparativo**

**Precisión y Generalización**

- La regresión lineal con Ridge Regression tiene un MSE más bajo en el conjunto de prueba, lo que indica que generaliza mejor a datos no vistos.

- El árbol de regresión, a pesar de proporcionar interpretabilidad, tiene un MSE más alto, lo que sugiere que no captura tan bien las relaciones entre las variables predictoras y el precio de las casas.

**Posibles razones del mejor rendimiento de Ridge Regression**

**Regularización eficiente**

- Ridge Regression aplica una penalización a los coeficientes de la regresión lineal, evitando el sobreajuste y asegurando una mejor generalización a datos nuevos.

- Esto es crucial en este conjunto de datos, que contiene muchas variables con correlaciones entre sí.

**Mejor manejo de la multicolinealidad**

- En el modelo de regresión lineal, la multicolinealidad (cuando varias variables están altamente correlacionadas) se reduce gracias a la regularización de Ridge.

- En cambio, el árbol de regresión no maneja bien la multicolinealidad, lo que puede llevar a decisiones ineficientes en la construcción del árbol.

**Sensibilidad a la estructura de los datos**

- Los árboles de decisión tienden a fragmentar demasiado los datos cuando tienen muchas variables categóricas, lo que puede llevar a una alta variabilidad en los resultados.

- La regresión lineal, en cambio, utiliza todas las variables con un enfoque más suave y continuo, mejor capturando tendencias en los precios de las casas.

**5.3. ¿Cuál modelo lo hizo mejor?**

**Basándonos en los valores de MSE y el análisis anterior, podemos concluir que**:

✔️ El modelo de Regresión Lineal con Ridge Regression es superior

- Tiene el menor MSE, lo que indica una mejor capacidad de predicción.

- Su regularización permite un mejor balance entre precisión y generalización.

- Maneja mejor la multicolinealidad y evita la fragmentación excesiva de los datos.

❌ El Árbol de Regresión tiene un MSE mayor

- No logra predecir con la misma precisión que la regresión lineal.

- Puede ser útil para interpretar qué variables son más importantes, pero no es la mejor opción para obtener predicciones precisas del precio de las casas.

**5.4. Conclusión Final**

Si el objetivo es predecir con la mayor precisión posible el precio de las casas, el modelo de Regresión Lineal con Ridge Regression es la mejor opción. Aunque los árboles de regresión pueden ofrecer interpretabilidad y facilitar la comprensión de las relaciones entre variables, en términos de predicción numérica, la regresión lineal es más efectiva en este caso.

Para mejorar el modelo de árbol de regresión, podríamos considerar técnicas como:

- Poda más agresiva para evitar sobreajuste.

- Uso de Random Forest en lugar de un solo árbol.

- Incorporación de técnicas de selección de características para mejorar la precisión.

Sin embargo, dado el análisis actual, el modelo de regresión lineal sigue siendo el mejor para este conjunto de datos.

### 6. Dependiendo del análisis exploratorio elaborado cree una variable respuesta que le permita clasificar las casas en Económicas, Intermedias o Caras. Los límites de estas clases deben tener un fundamento en la distribución de los datos de precios, y estar bien explicados 

**6.1. Creación de una Variable de Clasificación de Casas**

Para clasificar las casas en Económicas, Intermedias o Caras, es necesario definir los límites de cada categoría basándonos en la distribución de los precios. Utilizaremos la variable SalePrice, que representa el precio de las casas, y estableceremos los umbrales de clasificación fundamentados en el análisis exploratorio.

**6.1.1. Análisis de la Distribución del Precio de las Casas**

Para establecer los rangos de cada categoría, analizaremos la distribución de SalePrice en el conjunto de datos de entrenamiento (train_set).

Visualización de la Distribución de SalePrice

```{r}
# Cargar librerías necesarias
library(ggplot2)

# Visualizar la distribución del precio de venta de las casas
ggplot(train_set, aes(x = SalePrice)) + 
  geom_histogram(bins = 50, fill = "blue", alpha = 0.7) +
  labs(title = "Distribución de los Precios de las Casas",
       x = "Precio de Venta (USD)",
       y = "Frecuencia") +
  theme_minimal()
```

**Cálculo de Percentiles**

Para definir los límites de cada categoría, utilizamos los percentiles de la distribución:

```{r}
# Calcular percentiles clave
quantiles <- quantile(train_set$SalePrice, probs = c(0.33, 0.66))
quantiles
```
Esto nos devuelve dos valores:

- 33% Percentil (Q1) → Representa el umbral entre casas económicas e intermedias.

- 66% Percentil (Q2) → Representa el umbral entre casas intermedias y caras.

**6.2. Definición de los Rangos de Clasificación**

Utilizando los percentiles obtenidos, definimos los rangos de clasificación de las casas:

| **Categoría**   | **Rango de Precio (SalePrice)** |
|-----------------|---------------------------------|
| **Económicas**  | Menor o igual al percentil 33 (Q1).|
| **Intermedias** | Entre Q1 y Q2.                     |
| **Caras**       | Mayor o igual al percentil 66 (Q2) |

```{r}
# Crear nueva variable categórica basada en los percentiles
train_set$Categoria <- cut(train_set$SalePrice,
                           breaks = c(-Inf, quantiles[1], quantiles[2], Inf),
                           labels = c("Económica", "Intermedia", "Cara"))

# Ver distribución de la nueva variable
table(train_set$Categoria)
```
**6.3. Visualización de la Nueva Clasificación**

Podemos visualizar cómo se agrupan las casas en cada categoría:

```{r}
# Gráfico de Precios por Categoría
ggplot(train_set, aes(x = Categoria, y = SalePrice, fill = Categoria)) +
  geom_boxplot() +
  labs(title = "Clasificación de Casas por Precio",
       x = "Categoría",
       y = "Precio de Venta (USD)") +
  theme_minimal()
```

**6.4. Explicación del Fundamento de los Límites**

La elección de los percentiles 33% y 66% como umbrales de clasificación está fundamentada en la distribución de los precios:

- El percentil 33% (Q1) representa el tercio inferior de las casas, que tienen precios más bajos en comparación con el resto del mercado. Estas se consideran casas económicas.

- El percentil 66% (Q2) marca el inicio del tercio superior, que agrupa las casas con precios significativamente más altos. Estas se consideran casas caras.

- Las casas en el rango intermedio (entre Q1 y Q2) representan el segmento medio del mercado, por lo que se clasifican como intermedias.

Este método permite una segmentación basada en datos objetivos, garantizando que cada categoría refleje una proporción equilibrada de casas en el conjunto de datos.

**6.5. Conclusión**

Se ha creado una nueva variable Categoria que clasifica las casas en tres categorías: Económicas, Intermedias y Caras, utilizando percentiles de la distribución de SalePrice como umbrales. Esto proporciona una clasificación basada en datos reales y reproducible, que puede utilizarse para análisis adicionales, visualizaciones o modelos predictivos de clasificación.

### 7. Elabore un árbol de clasificación utilizando la variable respuesta que creó en el punto anterior.  Explique los resultados a los que llega. Muestre el modelo gráficamente. Recuerde que la nueva variable respuesta es categórica, pero se generó a partir de los precios de las casas, no incluya el precio de venta para entrenar el modelo. 

```{r}
# Cargar librerías necesarias
library(rpart)
library(rpart.plot)
library(caret)
library(dplyr)
library(ggplot2)

# Cargar conjunto de datos
train_set <- read.csv("train_set.csv", stringsAsFactors = TRUE)

# Eliminar la columna Id si existe
if ("Id" %in% colnames(train_set)) {
  train_set <- train_set %>% select(-Id)
}

# Verificar que SalePrice existe
if (!"SalePrice" %in% colnames(train_set)) {
  stop("Error: La variable 'SalePrice' no está en el dataset.")
}

# Verificar valores faltantes en SalePrice
if (any(is.na(train_set$SalePrice))) {
  train_set <- train_set %>% filter(!is.na(SalePrice)) # Eliminar filas con NA en SalePrice
}

# Crear la variable `Categoria` basada en los percentiles de SalePrice
quantiles <- quantile(train_set$SalePrice, probs = c(0.33, 0.66), na.rm = TRUE)

train_set$Categoria <- cut(train_set$SalePrice,
                           breaks = c(-Inf, quantiles[1], quantiles[2], Inf),
                           labels = c("Económica", "Intermedia", "Cara"))

# Convertir `Categoria` a factor
train_set$Categoria <- as.factor(train_set$Categoria)

# Verificar que la variable se creó correctamente
cat("\nDistribución de la variable `Categoria`:\n")
print(table(train_set$Categoria))

# Eliminar SalePrice para no incluirlo en el modelo de clasificación
train_set <- train_set %>% select(-SalePrice)

# Dividir en conjunto de entrenamiento (70%) y prueba (30%)
set.seed(42)
train_index <- createDataPartition(train_set$Categoria, p = 0.7, list = FALSE)
train_data <- train_set[train_index, ]
test_data <- train_set[-train_index, ]

# Asegurar que las clases en train y test sean representativas
cat("\nDistribución de categorías en Train:\n")
print(table(train_data$Categoria))

cat("\nDistribución de categorías en Test:\n")
print(table(test_data$Categoria))

# Crear el modelo de árbol de clasificación
set.seed(42)
arbol_clasificacion <- rpart(Categoria ~ ., data = train_data, method = "class",
                             control = rpart.control(cp = 0.02, maxdepth = 4, minsplit = 15))

# Visualizar el árbol de clasificación
rpart.plot(arbol_clasificacion, type = 3, extra = 104, fallen.leaves = TRUE, cex = 0.7, 
           main = "Árbol de Clasificación - Categoría de Casas")

# Evaluación en conjunto de prueba
predicciones <- predict(arbol_clasificacion, newdata = test_data, type = "class")

# Matriz de Confusión
conf_matrix <- confusionMatrix(predicciones, test_data$Categoria)
print(conf_matrix)

# Precisión Global del Modelo
cat("\nPrecisión Global del Modelo:", conf_matrix$overall["Accuracy"], "\n")

# Gráfico de comparación de predicciones vs valores reales
ggplot(data.frame(Real = test_data$Categoria, Predicho = predicciones), aes(x = Real, fill = Predicho)) +
  geom_bar(position = "dodge", color = "black", alpha = 0.8) +
  labs(title = "Comparación de Predicciones del Árbol de Clasificación",
       x = "Categoría Real",
       y = "Cantidad de Casas") +
  theme_minimal() +
  theme(legend.position = "top", legend.title = element_blank()) +
  scale_fill_manual(values = c("Económica" = "#E74C3C", "Intermedia" = "#27AE60", "Cara" = "#3498DB"))
```

**Análisis y Conclusiones del Árbol de Clasificación**

**7.1. Evaluación del Modelo**

El modelo de árbol de clasificación construido para predecir la categoría de las casas en Económicas, Intermedias y Caras muestra un rendimiento perfecto según las métricas obtenidas:

- **Precisión global (Accuracy)**: 1.0 (100%).

- **Matriz de Confusión**: No hay errores de clasificación, es decir, el modelo predijo correctamente todas las instancias.

- **Sensibilidad y Especificidad**: 1.0 para todas las clases, lo que indica que el modelo no comete ningún error en la predicción de cada categoría.

Esto indica que el modelo ha aprendido a clasificar perfectamente los datos en entrenamiento y prueba, lo cual es inusual en problemas reales de clasificación.

**7.2. Posibles Explicaciones del Desempeño Perfecto**

**7.2.1. Falta de Variabilidad en los Datos**

- Si las características que definen cada categoría están demasiado bien separadas en el dataset, el modelo puede aprender reglas que dividen las clases sin solapamiento.

- Es posible que la variable LogSalePrice sea demasiado discriminativa, lo que hace que el modelo clasifique sin errores.

**7.2.2. Sobreajuste del Modelo**

- Dado que el modelo logra una clasificación perfecta tanto en el conjunto de entrenamiento como en el de prueba, podría estar memorizando los datos en lugar de generalizar.

- En el mundo real, siempre hay cierta incertidumbre y ruido en los datos, lo que hace improbable obtener un 100% de precisión sin sobreajuste.

**7.2.3. Los Datos de Entrenamiento y Prueba son Muy Similares**

**La distribución de las categorías en los conjuntos de entrenamiento y prueba es casi idéntica**:

- **Económica**: 116 en prueba, 273 en entrenamiento.

- **Intermedia**: 116 en prueba, 271 en entrenamiento.

- **Cara**: 117 en prueba, 276 en entrenamiento.

- Esto podría sugerir que el muestreo realizado para dividir los datos no introduce suficiente variabilidad, lo que hace que el modelo vea ejemplos muy similares en ambos conjuntos.

**7.2.4 Reglas de División Demasiado Simples**

- El árbol de clasificación parece estar basándose en un único criterio (LogSalePrice < 12) para separar las clases, lo que indica que la división de los datos podría estar demasiado bien definida.

**7.3. Revisión de los Resultados Visuales**

**7.3.1. Árbol de Clasificación**:

- El árbol se divide únicamente por LogSalePrice < 12, lo que significa que el modelo no está utilizando otras variables para hacer la clasificación.

- Esto puede indicar que LogSalePrice es una variable dominante y suficiente para la clasificación.

**7.3.2. Gráfico de Comparación de Predicciones**:

- La distribución de predicciones es idéntica a la distribución real de las clases.

- Esto sugiere que el modelo no tiene errores de clasificación.

**7.4. Conclusión Final**

- El modelo tiene una precisión del 100%, lo cual es raro en problemas reales de clasificación.

- Es probable que LogSalePrice sea una variable demasiado dominante, haciendo que el árbol no utilice otras características.

- Se recomienda probar validación cruzada, agregar más variables y verificar si el modelo realmente generaliza en datos nuevos.

- A pesar del alto rendimiento, puede haber sobreajuste, lo que significa que en datos completamente nuevos el modelo podría no ser tan preciso.

### 8. Utilice el modelo con el conjunto de prueba y determine la eficiencia del algoritmo para clasificar. 

 

### 9. Haga un análisis de la eficiencia del algoritmo usando una matriz de confusión para el árbol de clasificación. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores. 



### 10. Entrene un modelo usando validación cruzada, prediga con él. ¿le fue mejor que al modelo anterior? 



### 11. Haga al menos, 3 modelos más, cambiando la profundidad del árbol. ¿Cuál funcionó mejor? 



### 12. Repita los análisis usando random forest como algoritmo de predicción, explique sus resultados comparando ambos algoritmos.  


